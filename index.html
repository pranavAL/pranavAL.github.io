<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pranav Agarwal</title>
  
  <meta name="author" content="Pranav Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
  <style>
    html {
            scroll-behavior: smooth;
        }
        #widget-container {
            position: fixed;
            bottom: 0;
            left: 0;
        }
        .timeline {
            display: flex;
            flex-direction: column;
            gap: 10px;
        } 

        .timeline li {
            display: flex;
            flex-direction: row;
            align-items: flex-start;
        }
        .timeline li div:first-child {
        min-width: 100px;
        }
        
        .scrollable-news {
          max-height: 400px; /* Adjust the maximum height as needed */
          overflow-y: scroll;
        }

        #blogs {
          margin-top: 40px;
          padding: 30px;
          background-color: #f7f7f7;
          border-radius: 10px;
        }
        
        #blogs h2 {
          font-size: 2em;
          color: #333;
          margin-bottom: 20px;
        }
        
        .blog-container {
          display: flex;
          flex-wrap: wrap;
          gap: 20px;
          justify-content: space-between;
        }
        
        .blog-entry {
          display: flex;
          flex-direction: column;
          width: calc(33.33% - 20px); /* Adjust this for more or fewer columns */
          background-color: white;
          border: 1px solid #ddd;
          border-radius: 10px;
          overflow: hidden;
          box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .blog-image {
          width: 100%;
          height: 180px;
          object-fit: cover;
        }
        
        .blog-content {
          padding: 15px;
          text-align: left;
        }
        
        .blog-content h3 {
          font-size: 1.5em;
          margin: 0 0 10px;
        }
        
        .blog-content h3 a {
          text-decoration: none;
          color: #0073e6;
        }
        
        .blog-content h3 a:hover {
          text-decoration: underline;
        }
        
        .blog-content p {
          font-size: 1em;
          color: #555;
        }
        
        .read-more {
          margin-top: 10px;
          font-size: 0.9em;
          color: #0073e6;
          text-decoration: none;
          font-weight: bold;
        }
        
        .read-more:hover {
          text-decoration: underline;
        }
        
        @media (max-width: 1024px) {
          .blog-entry {
            width: calc(50% - 20px); /* 2 columns on smaller screens */
          }
        }
        
        @media (max-width: 768px) {
          .blog-entry {
            width: 100%; /* Full width on mobile */
          }
        }
        section {
          padding: 50px 20px;
      }

/* Optional: Style the scrollbar for better visibility */
.project-grid::-webkit-scrollbar {
  height: 8px;
}

.project-grid::-webkit-scrollbar-track {
  background: #f1f1f1;
}

.project-grid::-webkit-scrollbar-thumb {
  background-color: #888;
  border-radius: 10px;
}

.project-grid::-webkit-scrollbar-thumb:hover {
  background: #555;
}

/* Wrapper Container */
.project-container {
  max-width: 800px; /* Adjust this value to control the width */
  margin: 0 auto; /* Center the container horizontally */
  padding: 0 20px; /* Optional: Add padding to the sides */
}

/* Grid Layout */
.project-grid {
  display: flex;
  gap: 20px; /* Reduce the gap */
  justify-content: center; /* Center items */
  align-items: start; /* Align items properly */
  padding: 10px; /* Add padding for spacing */
}

/* Project Card */
.project-card {
  text-align: center;
  text-align: center;
  border: 1px solid #e0e0e0;
  border-radius: 10px;
  padding: 20px 15px; /* Slight padding to maintain balance */
  background-color: #fff;
  box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
  transition: transform 0.2s, box-shadow 0.2s;
}

.project-card:hover {
  transform: translateY(-10px);
  box-shadow: 0px 8px 20px rgba(0, 0, 0, 0.2);
}

/* Project Image */
.project-logo {
  width: 100%; /* Allow the image to take full card width */
  max-height: 130px; /* Slightly increase height */
  object-fit: cover; /* Ensures image fits nicely */
  border-radius: 8px; /* Optional: Add rounded corners to the image */
  margin-bottom: 15px;
}

/* Project Title */
.project-title {
  font-size: 22px; /* Increase font size slightly */
  font-weight: bold;
  margin-bottom: 10px;
}

/* Links for Blog and Code */
.project-links {
  margin-top: 15px;
}

.project-links a {
  text-decoration: none;
  font-size: 17px; /* Slightly increase text size */
  color: #007bff;
  margin-right: 10px;
  transition: color 0.3s;
}

.project-links a:hover {
  color: #0056b3;
}

/* Responsive Design */
@media (max-width: 768px) {
  .project-grid {
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); /* Smaller cards on mobile */
    gap: 10px; /* Reduce the gap for small screens */
    overflow-x: auto; /* Allow horizontal scrolling */
    padding-bottom: 10px; /* Add space for scrollbar */
  }

  .project-card {
    height: auto; /* Allow height to adjust */
    padding: 15px 10px; /* Reduce padding for small screens */
  }

  .project-logo {
    max-height: 100px; /* Reduce image height for small screens */
  }

  .project-title {
    font-size: 18px; /* Reduce font size for small screens */
  }

  .project-links a {
    font-size: 14px; /* Reduce link font size for small screens */
  }
}

/* Section Heading */
.section-heading {
  font-size: 32px;
  text-align: center;
  padding: 20px;
  color: #333;
}

    </style>
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pranav Agarwal</name>
              </p>
              <p> I completed my Ph.D. at <a href="https://mila.quebec/en/">Mila</a> (advised by <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a> and <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>), with a focus on reinforcement learning for robotics and character animation. My research explored efficient reinforcement learning algorithms using improved prior modeling for robotic applications. Specifically, I have worked on:</p>
<ul>
  <li>World models (Transformer based) for sample-efficient reinforcement learning</li>
  <li>Automating reward modeling from large offline trajectories</li>
  <li>Continual Learning</li>
  <li>Applications in complex robotic systems, such as autonomous driving</li>
  <li>Interpreting decision-making of LLMs</li>
</ul>

<p>Previously, I was a student researcher at <a href="https://www.inria.fr/en">Inria</a>, collaborating with <a href="https://sites.google.com/view/nataliadiaz">Natalia Díaz-Rodríguez</a> and <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a>. I completed my Bachelor's in Electronics and Communication Engineering at <a href="https://www.iiitg.ac.in/">IIIT Guwahati</a>, where I was awarded the President's Gold Medal. During my undergraduate studies, I worked as a research intern at <a href="https://www.sutd.edu.sg/">SUTD</a> with Professor <a href="https://scholar.google.com/citations?user=6MjMhT4AAAAJ&hl=en">Gemma Roig</a>.</p>

<p><strong>Research Interests:</strong> Reinforcement Learning | Lifelong Learning | World Models | Video Models | Robotics | LLM Interpretability </p>

<p><strong>Hobbies:</strong> Outside of research, I enjoy long walks, capturing nature (<a href="https://www.instagram.com/pranaval_" target="_blank">check out my photos</a>), reading (<a href="books.html">see my book collection</a>), and lifting weights.</p>

<!-- <p style="color: #d9534f; font-weight: bold;">I’m currently on the job market and open to full-time positions. I’m also happy to collaborate—feel free to reach out!</p>               -->

              <p style="text-align:center">
                    [
                <a href="mailto:pranav.agarwal.2109@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/my_CV_2.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/pranavAL">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/Pranav_AL">Twitter</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=QFEzapMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/pranav-agarwal-6b4453114/">Linkedin</a>&nbsp/&nbsp
                <a href="#blogs">Projects</a>
]
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/prof4.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/prof4.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
       <h2>Experience & Education</h2>

        <table class="about-edu" width="100%">
        
          <!--────────── LINE 1 · LOGOS ──────────-->
          <tr>
            <td align="center" width="14%"><a href="https://wayve.ai"><img  src="images/wayve_logo.jpeg" alt="Wayve"  width="50%"></a></td>
            <td align="center" width="14%"><a href="https://mila.quebec/"><img src="images/mila.webp"        alt="Mila"   width="50%"></a></td>
            <td align="center" width="14%"><a href="https://www.cm-labs.com/"><img src="images/cmlabs.jpeg"   alt="CM-Labs"width="50%"></a></td>
            <td align="center" width="14%"><a href="https://www.inria.fr/en"><img  src="images/inria.png"     alt="Inria"  width="50%"></a></td>
          </tr>
        
          <!--────────── LINE 1 · TEXT ──────────-->
          <tr>
            <td align="center">Machine-Learning Research Intern<br><b>Wayve, Vancouver</b><br>May 2025 – Aug 2025</td>
            <td align="center">Graduate Researcher<br><b>Mila, Québec</b><br>Jan 2022 – Sept 2025</td>
            <td align="center">Research Student<br><b>CM-Labs</b><br>Jan 2022 – Sept 2022</td>
            <td align="center">Research Assistant<br><b>Inria, Paris</b><br>May 2019 – Apr 2021</td>
          </tr>
        
          <!--────────── LINE 2 · LOGOS ──────────-->
          <tr>
            <td align="center" width="14%"><a href="https://www.etsmtl.ca/"><img  src="images/ets.svg"  alt="ÉTS"  width="50%"></a></td>
            <td align="center" width="14%"><a href="https://www.sutd.edu.sg/"><img src="images/sutd.jpg" alt="SUTD" width="50%"></a></td>
            <td align="center" width="14%"><a href="https://www.iiitg.ac.in/"><img src="images/iitg.jpg" alt="IIITG"width="50%"></a></td>
            <td align="center" width="14%"><a href="https://iisc.ac.in/"><img     src="images/iisc.jpg" alt="IISc" width="50%"></a></td>
          </tr>
        
          <!--────────── LINE 2 · TEXT ──────────-->
          <tr>
            <td align="center">PhD Student<br><b>ÉTS, Montréal</b><br>Jan 2022 – Sept 2025</td>
            <td align="center">Research Intern<br><b>SUTD</b><br>May 2018 – Aug 2018</td>
            <td align="center">B.Tech ECE<br><b>IIIT Guwahati</b><br>Aug 2015 – May 2019</td>
            <td align="center">Research Intern<br><b>IISc, Bangalore</b><br>May 2017 – Aug 2017</td>
          </tr>
        
        </table>
        <h2>News</h2>
        <div class="scrollable-news">
        <ul class="timeline">
          <li>
            <div><b>June 2025</b>:</div>
            <div><b>Paper</b> - Our paper <a href="https://supernova-event.ai/">Interpreting Large Language Model Personality</a> was accepted at ICML 2025 workshop</a>.</div>
          </li>
          <li>
            <div><b>May 2025</b>:</div>
            <div><b>Position</b> - Started a research internship at <a href="https://wayve.ai/"> Wayve</a>, working on World Models and Offline-RL.</div>
          </li>
          <li>
            <div><b>March 2025</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://open-foundation-model.github.io/">SCI-FM @ ICLR 2025</a>.</div>
          </li>
          <li>
            <div><b>Feb 2025</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://delta-workshop.github.io/">ICLR 2025 Workshop DeLTa</a>.</div>
          </li>
          <li>
            <div><b>Feb 2025</b>:</div>
            <div><b>Blog</b> - New blog out: <a href="#blogs">Mamba: Can We Achieve Infinite Context Length?</a></div>
          </li>
          <li>
            <div><b>Jan 2025</b>:</div>
            <div><b>Under Review</b> - Continual Reinforcement Learning for Robotic Application</a>.</div>
          </li>
          <li>
            <div><b>July 2024</b>:</div>
            <div><b>Award</b> - ETS Substance Research Dissemination Scholarship worth 1000$</a>.</div>
          </li>
          <li>
            <div><b>June 2024</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://asia.siggraph.org/2024/">SIGGRAPH Asia</a>.</div>
          </li>
          <li>
            <div><b>May 2024</b>:</div>
            <div><b>Paper</b> - Our paper <a href="https://pranaval.github.io/DART/">Learning to play Atari in a World of Tokens</a> was accepted at ICML 2024</a>.</div>
          </li>
          <li>
            <div><b>Nov 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://2024.ieee-icra.org/">ICRA</a>.</div>
          </li>
          <li>
            <div><b>Oct 2023</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://aamer98.github.io/medical_decision_transformer/">Empowering Clinicians with MeDT: A Framework for Sepsis Treatment</a> was accepted at <b>Goal-Conditioned Reinforcement Learning Workshop, NeurIPS 2023 (<strong><span style="color: red;">Spotlight</span></strong>)</b>.</div>
          </li>
          <li>
            <div><b>Oct 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://sice-si.org/SII2024/">SII</a>.</div>
          </li>
          <li>
            <div><b>Sept 2023</b>:</div>
            <div><b>Exam</b> - Passed the Ph.D. proposal exam.</div>
          </li>
          <li>
            <div><b>Jul 2023</b>:</div>
            <div><b>Paper</b> - Preprint release of our work <a href="https://arxiv.org/pdf/2307.05979.pdf"> Transformers in Reinforcement Learning: A Survey</a>.</div>
          </li>
          <li>
            <div><b>Apr 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://iccv2023.thecvf.com/">ICCV</a> and <a href="https://ieee-iros.org/">IROS</a></b>.</div>
          </li>
          <li>
            <div><b>Dec 2022</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://arxiv.org/pdf/2211.07941.pdf">Automatic Evaluation of Excavator Operators using Learned Reward Functions</a> was accepted at <b>Reinforcement Learning for Real Life Workshop, Neurips 2022</b>.</div>
          </li>
          <li>
              <div><b>Nov 2022</b>:</div>
              <div><b>Reviewer</b> - Served as reviewer for  <a href="https://www.ieee-ras.org/publications/ra-l">Robotics and Automation Letters</a>.</div>
            </li>  
          <li>  
            <div><b>Sept 2022</b>:</div>
            <div><b>Position</b> - Fast-tracked to a PhD position at <a href="https://mila.quebec/">Mila</a>.</div>
          </li>
          <li>
            <div><b>Jun 2022</b>:</div>
            <div><b>Award</b> - Received an Exemption from International Tuition Fees for Graduate studies.</div>
          </li>
          <li>
            <div><b>Jan 2022</b>:</div>
            <div><b>Position</b> - Started Masters by Research at <a href="https://mila.quebec/">Mila</a>, in collaboration with <a href="https://www.cm-labs.com/en/">CM Labs</a>.</div>
          </li>
          <li>
            <div><b>Mar 2020</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://arxiv.org/pdf/2003.11743.pdf">Egoshots</a> was accepted at <b>Machine Learning in Real Life Workshop, ICLR 2020</b>.</div>
          </li>
          <li>
            <div><b>May 2019</b>:</div>
            <div><b>Position</b> - Started a research position at Inria.</div>
          </li>
          <li>
            <div><b>Apr 2019</b>:</div>
            <div><b>Graduation</b> - Graduated from IIIT Guwahati with President's Gold Medal.</div>
          </li>
          <li>
            <div><b>Mar 2019</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://ieeexplore.ieee.org/abstract/document/8971330">Learning to synthesize faces using voice clips for Cross-Modal biometric matching</a> was accepted at IEEE Region 10 Symposium (TENSYMP).</div>
          </li>
          <li>
            <div><b>Mar 2019</b>:</div>
            <div><b>Award</b> - Received the Best Technology Award (reward of 1500 USD) by Govt. of India.</div>
          </li>
          <li>
            <div><b>May 2018</b>:</div>
            <div><b>Position</b> - Started a Research Internship at <a href="https://www.sutd.edu.sg/">Singapore University of Technology and Design</a>.</div>
          </li>
        </ul>
      </div>
            <!--<h2>Research 	&#129302;</h2>-->
        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SNE.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://supernova-event.ai/">
                <papertitle>Supernova Event Dataset: Interpreting Large Language Models' Personality through Critical Event Analysis</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.iciuca.com/">Ioana Ciucă</a>,
              <br><br>
              <em> ICML 2025 Actionable Interpretability Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/abs/2506.12189">Paper</a> /
              <a href="https://github.com/pranavAL/Supernova-Event-Dataset">Code</a> /
              <a href="https://www.supernova-event.ai/">Webpage</a> /
              <a href="https://www.supernova-event.ai/#your-story">Demo</a> /
              <a href="https://huggingface.co/datasets/SupernovaEvent/SupernovaEventDataset">Dataset</a>
               
              <br>
              <p>
                In this work, we interpret the personality traits of Large Language Models (LLMs) using our proposed Supernova Event Dataset, which includes Wikipedia articles consisting of historical events, biographies, news events, and scientific discoveries. We benchmark models based on their identification and ranking of key life or discovery events, a complex task requiring causal reasoning. A second LLM acts as a judge to infer each model’s personality based on its event selection and interpretation. Our analysis show distinct traits, like emotional reasoning in Orca 2 and analytical framing in Qwen 2.5, enhancing interpretability and trust.
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px; width:25%; vertical-align:middle;">
              <img src="images/survey-full.gif" alt="elign" style="border-style:none;" width="350">
            </td>
            <td style="padding:20px; width:75%; vertical-align:middle;">
              <a href="https://pranavAL.github.io/transformers-in-rl-survey/">
                <papertitle>Transformers in Reinforcement Learning: A Survey</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>, 
              <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>, 
              <a href="https://mila.quebec/en/person/plstcharles/">Pierre-Luc St-Charles</a>, 
              <a href="https://www.linkedin.com/in/simon-prince-615bb9165/?originalSubdomain=ca">Simon J.D. Prince</a>, 
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em>Under Review (2023)</em>
              <br><br>
              <a href="https://arxiv.org/pdf/2307.05979.pdf">Paper</a> / 
              <a href="https://pranavAL.github.io/transformers-in-rl-survey/">Webpage</a>
              <br><br>
              <p>
                This survey explores the impact of transformers in reinforcement learning, addressing common RL challenges, while examining their applications in representation learning, policy optimization, and interpretability.
              </p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DART.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://pranaval.github.io/DART/">
                <papertitle>Learning to Play Atari in a World of Tokens</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em> International Conference on Machine Learning (ICML), 2024</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2406.01361">Paper</a> /
              <a href="https://github.com/pranavAL/DART">Code</a> /
              <a href="https://pranaval.github.io/DART/">Webpage</a> /
              <a href="">Slides</a> 
               
              <br>
              <p>
                This work introduces Discrete Abstract Representations for Transformer-based Learning (DART), a sample-efficient method that utilizes discrete representations to improve world modeling and learning behavior in reinforcement learning, achieving superior performance on the Atari 100k benchmark compared to existing methods.
            </td>
          </tr>



          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/medt_eval_gif_title.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Empowering Clinicians with MeDT: A Framework for Sepsis Treatment</papertitle>
              </a>
              <br>
              <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>,
              <strong>Pranav Agarwal</strong>,
              <a href="https://vmichals.github.io/">Vincent Michalski</a>,
              <a href="https://www.etsmtl.ca/en/research/professors/rnoumeir/">Rita Noumeir</a>,
              <a href="https://recherche.umontreal.ca/english/our-researchers/professors-directory/researcher/is/in15318/">Philippe Jouvet</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em> NeurIPS 2023 Goal-Conditioned Reinforcement Learning Workshop (<strong><span style="color: red;">Spotlight</span></strong>)</em>. 
              <br><br>
            
              <a href="">Paper</a> /
              <a href="https://github.com/Aamer98/MeDT">Code</a> /
              <a href="https://aamer98.github.io/medical_decision_transformer/">Webpage</a> /
              <a href="">Slides</a> 
        
              <br>
              <p>
                The Medical Decision Transformer (MeDT) leverages the transformer architecture to enhance offline reinforcement learning for sepsis treatment recommendations, utilizing a goal-conditioned RL paradigm that improves interpretability and clinician interactivity, while achieving competitive results on the MIMIC-III dataset.
            </td>
          </tr> 

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TPTO.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>TPTO: A Transformer-PPO based Task Offloading Solution for Edge Computing Environments</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.ca/citations?user=z7lBJwgAAAAJ&hl=en">Niloofar Gholipour</a>,
              <a href="https://www.marcosassuncao.com/">Marcos Dias de Assuncao</a>,
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.juliengs.ca/">Julien Gascon-Samson</a>,
              <a href="https://scholar.google.com/citations?user=7xN6JqYAAAAJ&hl=en">Rajkumar Buyya</a>,
              <br><br>
              <em> IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS)</em>. 
              <br><br>
          
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10476301">Paper</a> /
              <a href="">Code</a> /
              <a href="">Webpage</a> /
              <a href="">Slides</a> 
              
              <br>
              <p>
                This paper introduces TPTO, a Deep Reinforcement Learning approach that utilizes Transformer and Proximal Policy Optimization to efficiently offload dependent IoT tasks to edge servers, significantly reducing latency for IoT applications compared to state-of-the-art methods.
              </td>
          </tr> 
                
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crane.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2211.07941.pdf">
                <papertitle>Automatic Evaluation of Excavator Operators using Learned Reward Functions</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.linkedin.com/in/marekteichmann/?originalSubdomain=ca">Marek Teichmann</a>,
              <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em>NeurIPS 2022 Reinforcement Learning for Real Life Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2211.07941.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/InvRL_Auto-Evaluate">Code</a> /
              <a href="https://drive.google.com/file/d/1jR1otOAu8zrY8mkhUOUZW9jkBOAKK71Z/view?usp=share_link">Video</a> /
              <a href="https://docs.google.com/presentation/d/1KEXmwOWRN_q6o5lPVk83O8mnfiCV-0kpGrnj2USp1fw/edit?usp=sharing">Slides</a>
               
              <p>A novel automatic evaluation strategy for excavator operators is proposed, utilizing machine dynamics and safety criteria, which is then validated through reinforcement learning in a simulation, resulting in safer and more realistic excavator maneuvering policies.
              </p>
            </td>
          </tr>
               

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/carla.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2103.09189.pdf">
                <papertitle>Goal-constrained Sparse Reinforcement Learning for End-to-End Driving</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.linkedin.com/in/pierre-de-beaucorps-06064099/">Pierre de Beaucorps</a>,
              <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a>
              <br><br>
              <em>In submission (2021)</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2103.09189.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/Goal-constrained-Sparse-Reinforcement-Learning-for-End-to-End-Driving">Code</a> /
              <a href="https://www.youtube.com/watch?v=6mD9OwrAroU">Video</a> 
               
              <br>
              <p> A curriculum-based deep reinforcement learning approach for end-to-end driving is proposed, using sparse rewards and navigation view maps to achieve generalization on unseen roads and longer distances.
</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/elign.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2003.11743.pdf">
                <papertitle>Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=fLHBgLMAAAAJ&hl=en">Alejandro Betancourt</a>,
              <a href="https://www.linkedin.com/in/vanapanagiotou/?originalSubdomain=gr">Vana Panagiotou</a>,
              <a href="https://sites.google.com/view/nataliadiaz">Natalia Diaz-Rodriguez</a>
              <br><br>
              <em>Machine Learning in Real Life (ML-IRL) ICLR 2020 Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2003.11743.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/Semantic_Fidelity-and-Egoshots">Code</a> /
              <a href="https://www.youtube.com/watch?v=TFzxFfI90sc">Video</a> /
              <a href="https://docs.google.com/presentation/d/1UOadIVy_CYFsFC5POjfgUxvwxST35P6kDXUp2Au4kVI/edit#slide=id.p">Slides</a>
               
              <br>
              <p>
                A new image captioning dataset, Egoshots, is introduced alongside a novel evaluation metric, Semantic Fidelity, to address biases in existing models and enable caption assessment without annotations.
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/clap.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8971330">
                <papertitle>Learning to synthesize faces using voice clips for Cross-Modal biometric matching</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=_MwJODcAAAAJ&hl=en">Soumyajit Poddar</a>,
              <a href="https://scholar.google.co.in/citations?user=v3U0HZ4AAAAJ&hl=en">Anakhi Hazarika</a>,
              <a href="https://scholar.google.com/citations?user=s73BsKIAAAAJ&hl=en">Hafizur Rahaman</a>
              <br><br>
              <em> 2019 IEEE Region 10 Symposium (TENSYMP)</em>. 
              <br><br>
              
              <a href="https://ieeexplore.ieee.org/abstract/document/8971330">Paper</a> /
              <a href="https://github.com/pranavAL/Cross_modal_Biometric_matching">Code</a>
              
              <br>
              <p>
                A framework for cross-modal biometric matching is proposed, generating faces from voice clips using various generative networks, with RC-GAN achieving the best identity accuracy of 84.52% and VAE producing the highest quality images.
            </td>
          </tr>

          
        </tbody></table>

      </td>
    </tr>
  </table>

<!-- Add this after your Research section -->
<section id="blogs">
  <h2 class="section-heading">Projects</h2>
  <div class="project-container"></div>  
  <div class="project-grid">
    <div class="project-card">
      <img src="Projects/project2/3.gif" alt="Mamba" class="project-logo">
      <div class="project-title">Mamba: Can We Achieve Infinite Context Length?</div>
      <div class="project-links">
        <a href="Projects/project2.html" target="_blank">Blog</a> 
        <a href="https://github.com/pranavAL/deep-learning-from-scratch/tree/main/mamba" target="_blank">Code</a>
      </div>
    </div>
    <div class="project-card">
      <img src="Projects/project1/diffusion_process_with_timesteps.gif" alt="Diffusion Models" class="project-logo">
      <div class="project-title">Diffusion Models</div>
      <div class="project-links">
        <a href="Projects/project1.html" target="_blank">Blog</a> 
        <a href="https://github.com/pranavAL/deep-learning-from-scratch/tree/main/diffusion_models" target="_blank">Code</a>
      </div>
    </div>
    <!-- Add more project cards as needed -->
  </div>
  </div>
</section>
    
    <!-- Add more project cards as needed -->
</section>

<div style="text-align: center;">
    <div style="display: inline-block; margin-top: 40px;">
        <table class="analytics">
            <tr>
                <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=150&t=n&d=7GitBdIjM6_HrTVgbGuqjaG9RLy_0UXsikjyC2QZBVQ"></script>
            </tr>
        </table>
    </div>
</div>abl>
</div>
  
 </body>

</html>
