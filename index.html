<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pranav Agarwal</title>
  
  <meta name="author" content="Pranav Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
  <style>
        #widget-container {
            position: fixed;
            bottom: 0;
            left: 0;
        }
        .timeline {
            display: flex;
            flex-direction: column;
            gap: 10px;
        } 

        .timeline li {
            display: flex;
            flex-direction: row;
            align-items: flex-start;
        }
        .timeline li div:first-child {
        min-width: 100px;
        }
        
        .scrollable-news {
          max-height: 400px; /* Adjust the maximum height as needed */
          overflow-y: scroll;
        }
    </style>
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pranav Agarwal</name>
              </p>
              <p>I am a Ph.D. candidate at <a href="https://mila.quebec/en/">Mila</a>, advised by <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a> and <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>, working on reinforcement Learning for robotic applications and character animation. My research interests are in modeling efficient reinforcement learning algorithms utilizing large generative models. Towards this goal, I have worked on generative models (Transformers) for sample-efficient reinforcement learning and automating reward modeling (from large offline trajectories) for complex robotic applications like excavator automation. </p>
              <p> Previously, I was a student researcher at <a href="https://www.inria.fr/en">Inria</a> where I collaborated with <a href="https://sites.google.com/view/nataliadiaz">Natalia DÃ­az-RodrÃ­guez</a> and
         <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de CHARETTE</a>. I completed my Bachelors in Electronics and Communication Engineering at <a href="https://www.iiitg.ac.in/">IIIT Guwahati</a>, where I was awarded the President's Gold Medal. During my bachelor's I worked as a research intern at <a href="https://www.sutd.edu.sg/">SUTD</a> with Professor <a href="https://scholar.google.com/citations?user=6MjMhT4AAAAJ&hl=en">Gemma Roig</a>.
              <p> <span style="color: red;">I'm looking for research positions and open to collaborations. Feel free to reach out!</span>  
        
              <p style="text-align:center">
                    [
                <a href="mailto:pranav.agarwal.2109@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Agarwal_Pranav_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/pranavAL">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/Pranav_AL">Twitter</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=QFEzapMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/pranav-agarwal-6b4453114//">Linkedin</a>
]
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/prof3.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/prof3.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <h2>Background</h2> -->
        <p> 
              </p>
              <p>
              </p>
        <h2>News</h2>
        <div class="scrollable-news">
        <ul class="timeline">
          <li>
            <div><b>July 2024</b>:</div>
            <div><b>Award</b> - ETS Substance Research Dissemination Scholarship worth 1000$</a>.</div>
          </li>
          <li>
            <div><b>June 2024</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://asia.siggraph.org/2024/">SIGGRAPH Asia</a>.</div>
          </li>
          <li>
            <div><b>May 2024</b>:</div>
            <div><b>Paper</b> - Our paper <a href="https://pranaval.github.io/DART/">Learning to play Atari in a World of Tokens</a> was accepted at ICML 2024</a>.</div>
          </li>
          <li>
            <div><b>Nov 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://2024.ieee-icra.org/">ICRA</a>.</div>
          </li>
          <li>
            <div><b>Oct 2023</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://aamer98.github.io/medical_decision_transformer/">Empowering Clinicians with MeDT: A Framework for Sepsis Treatment</a> was accepted at <b>Goal-Conditioned Reinforcement Learning Workshop, NeurIPS 2023 (<strong><span style="color: red;">Spotlight</span></strong>)</b>.</div>
          </li>
          <li>
            <div><b>Oct 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://sice-si.org/SII2024/">SII</a>.</div>
          </li>
          <li>
            <div><b>Sept 2023</b>:</div>
            <div><b>Exam</b> - Passed the Ph.D. proposal exam.</div>
          </li>
          <li>
            <div><b>Jul 2023</b>:</div>
            <div><b>Paper</b> - Preprint release of our work <a href="https://arxiv.org/pdf/2307.05979.pdf"> Transformers in Reinforcement Learning: A Survey</a>.</div>
          </li>
          <li>
            <div><b>Apr 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://iccv2023.thecvf.com/">ICCV</a> and <a href="https://ieee-iros.org/">IROS</a></b>.</div>
          </li>
          <li>
            <div><b>Dec 2022</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://arxiv.org/pdf/2211.07941.pdf">Automatic Evaluation of Excavator Operators using Learned Reward Functions</a> was accepted at <b>Reinforcement Learning for Real Life Workshop, Neurips 2022</b>.</div>
          </li>
          <li>
              <div><b>Nov 2022</b>:</div>
              <div><b>Reviewer</b> - Served as reviewer for  <a href="https://www.ieee-ras.org/publications/ra-l">Robotics and Automation Letters</a>.</div>
            </li>  
          <li>  
            <div><b>Sept 2022</b>:</div>
            <div><b>Position</b> - Fast-tracked to a PhD position at <a href="https://mila.quebec/">Mila</a>.</div>
          </li>
          <li>
            <div><b>Jun 2022</b>:</div>
            <div><b>Award</b> - Received an Exemption from International Tuition Fees for Graduate studies.</div>
          </li>
          <li>
            <div><b>Jan 2022</b>:</div>
            <div><b>Position</b> - Started Masters by Research at <a href="https://mila.quebec/">Mila</a>, in collaboration with <a href="https://www.cm-labs.com/en/">CM Labs</a>.</div>
          </li>
          <li>
            <div><b>Mar 2020</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://arxiv.org/pdf/2003.11743.pdf">Egoshots</a> was accepted at <b>Machine Learning in Real Life Workshop, ICLR 2020</b>.</div>
          </li>
          <li>
            <div><b>May 2019</b>:</div>
            <div><b>Position</b> - Started a research position at Inria.</div>
          </li>
          <li>
            <div><b>Apr 2019</b>:</div>
            <div><b>Graduation</b> - Graduated from IIIT Guwahati with President's Gold Medal.</div>
          </li>
          <li>
            <div><b>Mar 2019</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://ieeexplore.ieee.org/abstract/document/8971330">Learning to synthesize faces using voice clips for Cross-Modal biometric matching</a> was accepted at IEEE Region 10 Symposium (TENSYMP).</div>
          </li>
          <li>
            <div><b>Mar 2019</b>:</div>
            <div><b>Award</b> - Received the Best Technology Award (reward of 1500 USD) by Govt. of India.</div>
          </li>
          <li>
            <div><b>May 2018</b>:</div>
            <div><b>Position</b> - Started a Research Internship at <a href="https://www.sutd.edu.sg/">Singapore University of Technology and Design</a>.</div>
          </li>
        </ul>
      </div>
            <!--<h2>Research 	&#129302;</h2>-->
        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px; width:25%; vertical-align:middle;">
              <img src="images/survey-full.gif" alt="elign" style="border-style:none;" width="350">
            </td>
            <td style="padding:20px; width:75%; vertical-align:middle;">
              <a href="https://pranavAL.github.io/transformers-in-rl-survey/">
                <papertitle>Transformers in Reinforcement Learning: A Survey</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>, 
              <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>, 
              <a href="https://mila.quebec/en/person/plstcharles/">Pierre-Luc St-Charles</a>, 
              <a href="https://www.linkedin.com/in/simon-prince-615bb9165/?originalSubdomain=ca">Simon J.D. Prince</a>, 
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em>Under Review (2023)</em>
              <br><br>
              <a href="https://arxiv.org/pdf/2307.05979.pdf">Paper</a> / 
              <a href="https://pranavAL.github.io/transformers-in-rl-survey/">Webpage</a>
              <br><br>
              <p>
                This survey explores the impact of transformers in reinforcement learning, addressing common RL challenges, while examining their applications in representation learning, policy optimization, and interpretability.
              </p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DART.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://pranaval.github.io/DART/">
                <papertitle>Learning to Play Atari in a World of Tokens</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em> International Conference on Machine Learning (ICML), 2024</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2406.01361">Paper</a> /
              <a href="https://github.com/pranavAL/DART">Code</a> /
              <a href="https://pranaval.github.io/DART/">Webpage</a> /
              <a href="">Slides</a> 
               
              <br>
              <p>
                This work introduces Discrete Abstract Representations for Transformer-based Learning (DART), a sample-efficient method that utilizes discrete representations to improve world modeling and learning behavior in reinforcement learning, achieving superior performance on the Atari 100k benchmark compared to existing methods.
            </td>
          </tr>



          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/medt_eval_gif_title.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Empowering Clinicians with MeDT: A Framework for Sepsis Treatment</papertitle>
              </a>
              <br>
              <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>,
              <strong>Pranav Agarwal</strong>,
              <a href="https://vmichals.github.io/">Vincent Michalski</a>,
              <a href="https://www.etsmtl.ca/en/research/professors/rnoumeir/">Rita Noumeir</a>,
              <a href="https://recherche.umontreal.ca/english/our-researchers/professors-directory/researcher/is/in15318/">Philippe Jouvet</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em> NeurIPS 2023 Goal-Conditioned Reinforcement Learning Workshop (<strong><span style="color: red;">Spotlight</span></strong>)</em>. 
              <br><br>
            
              <a href="">Paper</a> /
              <a href="https://github.com/Aamer98/MeDT">Code</a> /
              <a href="https://aamer98.github.io/medical_decision_transformer/">Webpage</a> /
              <a href="">Slides</a> 
        
              <br>
              <p>
                The Medical Decision Transformer (MeDT) leverages the transformer architecture to enhance offline reinforcement learning for sepsis treatment recommendations, utilizing a goal-conditioned RL paradigm that improves interpretability and clinician interactivity, while achieving competitive results on the MIMIC-III dataset.
            </td>
          </tr> 

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TPTO.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>TPTO: A Transformer-PPO based Task Offloading Solution for Edge Computing Environments</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.ca/citations?user=z7lBJwgAAAAJ&hl=en">Niloofar Gholipour</a>,
              <a href="https://www.marcosassuncao.com/">Marcos Dias de Assuncao</a>,
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.juliengs.ca/">Julien Gascon-Samson</a>,
              <a href="https://scholar.google.com/citations?user=7xN6JqYAAAAJ&hl=en">Rajkumar Buyya</a>,
              <br><br>
              <em> IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS)</em>. 
              <br><br>
          
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10476301">Paper</a> /
              <a href="">Code</a> /
              <a href="">Webpage</a> /
              <a href="">Slides</a> 
              
              <br>
              <p>
                This paper introduces TPTO, a Deep Reinforcement Learning approach that utilizes Transformer and Proximal Policy Optimization to efficiently offload dependent IoT tasks to edge servers, significantly reducing latency for IoT applications compared to state-of-the-art methods.
              </td>
          </tr> 
                
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crane.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2211.07941.pdf">
                <papertitle>Automatic Evaluation of Excavator Operators using Learned Reward Functions</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.linkedin.com/in/marekteichmann/?originalSubdomain=ca">Marek Teichmann</a>,
              <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em>NeurIPS 2022 Reinforcement Learning for Real Life Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2211.07941.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/InvRL_Auto-Evaluate">Code</a> /
              <a href="https://drive.google.com/file/d/1jR1otOAu8zrY8mkhUOUZW9jkBOAKK71Z/view?usp=share_link">Video</a> /
              <a href="https://docs.google.com/presentation/d/1KEXmwOWRN_q6o5lPVk83O8mnfiCV-0kpGrnj2USp1fw/edit?usp=sharing">Slides</a>
               
              <p>A novel automatic evaluation strategy for excavator operators is proposed, utilizing machine dynamics and safety criteria, which is then validated through reinforcement learning in a simulation, resulting in safer and more realistic excavator maneuvering policies.
              </p>
            </td>
          </tr>
               

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/carla.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2103.09189.pdf">
                <papertitle>Goal-constrained Sparse Reinforcement Learning for End-to-End Driving</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.linkedin.com/in/pierre-de-beaucorps-06064099/">Pierre de Beaucorps</a>,
              <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a>
              <br><br>
              <em>In submission (2021)</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2103.09189.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/Goal-constrained-Sparse-Reinforcement-Learning-for-End-to-End-Driving">Code</a> /
              <a href="https://www.youtube.com/watch?v=6mD9OwrAroU">Video</a> 
               
              <br>
              <p> A curriculum-based deep reinforcement learning approach for end-to-end driving is proposed, using sparse rewards and navigation view maps to achieve generalization on unseen roads and longer distances.
</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/elign.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2003.11743.pdf">
                <papertitle>Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=fLHBgLMAAAAJ&hl=en">Alejandro Betancourt</a>,
              <a href="https://www.linkedin.com/in/vanapanagiotou/?originalSubdomain=gr">Vana Panagiotou</a>,
              <a href="https://sites.google.com/view/nataliadiaz">Natalia Diaz-Rodriguez</a>
              <br><br>
              <em>Machine Learning in Real Life (ML-IRL) ICLR 2020 Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2003.11743.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/Semantic_Fidelity-and-Egoshots">Code</a> /
              <a href="https://www.youtube.com/watch?v=TFzxFfI90sc">Video</a> /
              <a href="https://docs.google.com/presentation/d/1UOadIVy_CYFsFC5POjfgUxvwxST35P6kDXUp2Au4kVI/edit#slide=id.p">Slides</a>
               
              <br>
              <p>
                A new image captioning dataset, Egoshots, is introduced alongside a novel evaluation metric, Semantic Fidelity, to address biases in existing models and enable caption assessment without annotations.
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/clap.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8971330">
                <papertitle>Learning to synthesize faces using voice clips for Cross-Modal biometric matching</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=_MwJODcAAAAJ&hl=en">Soumyajit Poddar</a>,
              <a href="https://scholar.google.co.in/citations?user=v3U0HZ4AAAAJ&hl=en">Anakhi Hazarika</a>,
              <a href="https://scholar.google.com/citations?user=s73BsKIAAAAJ&hl=en">Hafizur Rahaman</a>
              <br><br>
              <em> 2019 IEEE Region 10 Symposium (TENSYMP)</em>. 
              <br><br>
              
              <a href="https://ieeexplore.ieee.org/abstract/document/8971330">Paper</a> /
              <a href="https://github.com/pranavAL/Cross_modal_Biometric_matching">Code</a>
              
              <br>
              <p>
                A framework for cross-modal biometric matching is proposed, generating faces from voice clips using various generative networks, with RC-GAN achieving the best identity accuracy of 84.52% and VAE producing the highest quality images.
            </td>
          </tr>

          
        </tbody></table>

      </td>
    </tr>
  </table>

<!-- Optional:
  <section id="projects" style="padding: 50px 0; background-color: #f9f9f9;">
    <h2 style="text-align: center; font-family: 'Arial', sans-serif; color: #333; font-size: 36px; letter-spacing: 1px; margin-bottom: 30px;">
      Projects ðŸ¤–
    </h2>
    <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 20px; padding: 20px;">
       
       Block for Project 1
       <div style="flex: 1 1 30%; max-width: 300px; background-color: #fff; border: 1px solid #e0e0e0; padding: 20px; border-radius: 10px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1); transition: transform 0.3s;">
          <h3 style="font-family: 'Arial', sans-serif; color: #555;">Pruning a Vision Transformer</h3>
          <p style="color: #777;">Short description of the project goes here. Explain what the project does and why itâ€™s cool.</p>
          <a href="https://github.com/username/project1" target="_blank" style="color: #2196f3; text-decoration: none; font-weight: bold;">View Project &rarr;</a>
       </div>
       
       <!-- Block for Project 2
       <div style="flex: 1 1 30%; max-width: 300px; background-color: #fff; border: 1px solid #e0e0e0; padding: 20px; border-radius: 10px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1); transition: transform 0.3s;">
          <h3 style="font-family: 'Arial', sans-serif; color: #555;">Project Title 2</h3>
          <p style="color: #777;">Short description of the project goes here. Briefly highlight key features.</p>
          <a href="https://github.com/username/project2" target="_blank" style="color: #2196f3; text-decoration: none; font-weight: bold;">View Project &rarr;</a>
       </div> -->
  
       <!-- Add more project blocks as needed -->
    <!-- </div> -->
  </section>
  
  <!-- Optional: Hover effect -->
  <!-- <style>
    #projects div:hover {
      transform: scale(1.05);
      box-shadow: 0px 8px 16px rgba(0, 0, 0, 0.2);
    }
  </style> -->


  <table class="about-edu" width="100%">
    <tr>
      <!-- Row 1: Logos -->
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://mila.quebec/"><img src="images/mila.webp" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.etsmtl.ca/"><img src="images/ets.svg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.cm-labs.com/"><img src="images/cmlabs.jpeg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.inria.fr/en"><img src="images/inria.png" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.iiitg.ac.in/"><img src="images/iitg.jpg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.sutd.edu.sg/"><img src="images/sutd.jpg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://iisc.ac.in/"><img src="images/iisc.jpg" width="50%"></a>
      </td>
    </tr>
    
    <!-- Row 2: Descriptions -->
    <tr>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        PhD Student<br><b>Mila, QuÃ©bec</b><br>Jan 2022
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        PhD Student<br><b>Ã‰TS, Montreal</b><br>Jan 2022
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Student<br><b>CM-Labs</b><br>Jan 2022 - Sept 2022
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Assistant<br><b>Inria, Paris</b><br>May 2019 - April 2021
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        B.Tech ECE<br><b>IIIT Guwahati</b><br>Aug 2015 - May 2019
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Intern<br><b>SUTD</b><br>May 2018 - Aug 2018
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Intern<br><b>IISc, Bangalore</b><br>May 2017 - Aug 2017
      </td>
    </tr>
  </table>


<div style="text-align: center;">
    <div style="display: inline-block; margin-top: 40px;">
        <table class="analytics">
            <tr>
                <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=150&t=n&d=7GitBdIjM6_HrTVgbGuqjaG9RLy_0UXsikjyC2QZBVQ"></script>
            </tr>
        </table>
    </div>
</div>abl>
</div>
  
 </body>

</html>
