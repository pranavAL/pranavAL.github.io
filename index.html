<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pranav Agarwal</title>
  
  <meta name="author" content="Pranav Agarwal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
  <style>
    html {
            scroll-behavior: smooth;
        }
        #widget-container {
            position: fixed;
            bottom: 0;
            left: 0;
        }
        .timeline {
            display: flex;
            flex-direction: column;
            gap: 10px;
        } 

        .timeline li {
            display: flex;
            flex-direction: row;
            align-items: flex-start;
        }
        .timeline li div:first-child {
        min-width: 100px;
        }
        
        .scrollable-news {
          max-height: 400px; /* Adjust the maximum height as needed */
          overflow-y: scroll;
        }

        #blogs {
          margin-top: 40px;
          padding: 30px;
          background-color: #f7f7f7;
          border-radius: 10px;
        }
        
        #blogs h2 {
          font-size: 2em;
          color: #333;
          margin-bottom: 20px;
        }
        
        .blog-container {
          display: flex;
          flex-wrap: wrap;
          gap: 20px;
          justify-content: space-between;
        }
        
        .blog-entry {
          display: flex;
          flex-direction: column;
          width: calc(33.33% - 20px); /* Adjust this for more or fewer columns */
          background-color: white;
          border: 1px solid #ddd;
          border-radius: 10px;
          overflow: hidden;
          box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        .blog-image {
          width: 100%;
          height: 180px;
          object-fit: cover;
        }
        
        .blog-content {
          padding: 15px;
          text-align: left;
        }
        
        .blog-content h3 {
          font-size: 1.5em;
          margin: 0 0 10px;
        }
        
        .blog-content h3 a {
          text-decoration: none;
          color: #0073e6;
        }
        
        .blog-content h3 a:hover {
          text-decoration: underline;
        }
        
        .blog-content p {
          font-size: 1em;
          color: #555;
        }
        
        .read-more {
          margin-top: 10px;
          font-size: 0.9em;
          color: #0073e6;
          text-decoration: none;
          font-weight: bold;
        }
        
        .read-more:hover {
          text-decoration: underline;
        }
        
        @media (max-width: 1024px) {
          .blog-entry {
            width: calc(50% - 20px); /* 2 columns on smaller screens */
          }
        }
        
        @media (max-width: 768px) {
          .blog-entry {
            width: 100%; /* Full width on mobile */
          }
        }
        section {
          padding: 50px 20px;
      }
/* Project Grid with Horizontal Scroll and Centering */
.project-grid {
  display: flex;
  gap: 20px;
  padding: 20px;
  justify-content: center; /* Center the first project */
  overflow-x: auto;  /* Enable horizontal scrolling */
  white-space: nowrap;  /* Ensure the items stay in a single row */
  transition: justify-content 0.5s ease;  /* Smooth transition when more projects are added */
}

/* Optional: Style the scrollbar for better visibility */
.project-grid::-webkit-scrollbar {
  height: 8px;
}

.project-grid::-webkit-scrollbar-track {
  background: #f1f1f1;
}

.project-grid::-webkit-scrollbar-thumb {
  background-color: #888;
  border-radius: 10px;
}

.project-grid::-webkit-scrollbar-thumb:hover {
  background: #555;
}

/* Project Card */
.project-card {
  flex: 0 0 auto;
  width: 350px; /* Keep the width */
  height: 180px; /* Slightly increase height */
  text-align: center;
  border: 1px solid #e0e0e0;
  border-radius: 10px;
  padding: 20px 15px; /* Slight padding to maintain balance */
  background-color: #fff;
  box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
  transition: transform 0.2s, box-shadow 0.2s;
  position: relative;
}

.project-card:hover {
  transform: translateY(-10px);
  box-shadow: 0px 8px 20px rgba(0, 0, 0, 0.2);
}

/* Project Image */
.project-logo {
  width: 100%; /* Allow the image to take full card width */
  max-height: 130px; /* Slightly increase height */
  object-fit: cover; /* Ensures image fits nicely */
  margin-bottom: 15px;
}

/* Project Title */
.project-title {
  font-size: 22px; /* Increase font size slightly */
  font-weight: bold;
  margin-bottom: 10px;
}

/* Links for Blog and Code */
.project-links {
  margin-top: 15px;
}

.project-links a {
  text-decoration: none;
  font-size: 17px; /* Slightly increase text size */
  color: #007bff;
  margin-right: 10px;
  transition: color 0.3s;
}

.project-links a:hover {
  color: #0056b3;
}

/* Project Description */
.project-description {
  display: none; /* Hide the description */
}

/* Responsive Design */
@media (max-width: 768px) {
  .project-grid {
      justify-content: start;  /* Align items to the start for small screens */
      overflow-x: auto;  /* Allow horizontal scrolling on small screens as well */
  }
}
      .section-heading {
        font-size: 32px;
        text-align: center;
        padding: 20px;
        color: #333;
    }

    </style>
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pranav Agarwal</name>
              </p>
              <p>I am a Ph.D. candidate at <a href="https://mila.quebec/en/">Mila</a>, advised by <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a> and <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>, focusing on reinforcement learning for robotics and character animation. My research explores efficient reinforcement learning algorithms using improved prior modeling for robotic applications. Toward this goal, I have worked on generative models (Transformers) for sample-efficient reinforcement learning and automating reward modeling (from large offline trajectories) for complex robotic applications like excavator automation. </p>
              <p> Previously, I was a student researcher at <a href="https://www.inria.fr/en">Inria</a> where I collaborated with <a href="https://sites.google.com/view/nataliadiaz">Natalia Díaz-Rodríguez</a> and
         <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de CHARETTE</a>. I completed my Bachelors in Electronics and Communication Engineering at <a href="https://www.iiitg.ac.in/">IIIT Guwahati</a>, where I was awarded the President's Gold Medal. During my bachelor's I worked as a research intern at <a href="https://www.sutd.edu.sg/">SUTD</a> with Professor <a href="https://scholar.google.com/citations?user=6MjMhT4AAAAJ&hl=en">Gemma Roig</a>.
              <p> <span style="color: red;">I'm looking for research positions and open to collaborations. Feel free to reach out!</span>  
        
              <p style="text-align:center">
                    [
                <a href="mailto:pranav.agarwal.2109@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/Agarwal_Pranav_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/pranavAL">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/Pranav_AL">Twitter</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=QFEzapMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/pranav-agarwal-6b4453114//">Linkedin</a>&nbsp/&nbsp
                <a href="#blogs">Projects</a>
]
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/prof3.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/prof3.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <h2>Background</h2> -->
        <p> 
              </p>
              <p>
              </p>
        <h2>News</h2>
        <div class="scrollable-news">
        <ul class="timeline">
          <li>
            <div><b>July 2024</b>:</div>
            <div><b>Award</b> - ETS Substance Research Dissemination Scholarship worth 1000$</a>.</div>
          </li>
          <li>
            <div><b>June 2024</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://asia.siggraph.org/2024/">SIGGRAPH Asia</a>.</div>
          </li>
          <li>
            <div><b>May 2024</b>:</div>
            <div><b>Paper</b> - Our paper <a href="https://pranaval.github.io/DART/">Learning to play Atari in a World of Tokens</a> was accepted at ICML 2024</a>.</div>
          </li>
          <li>
            <div><b>Nov 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://2024.ieee-icra.org/">ICRA</a>.</div>
          </li>
          <li>
            <div><b>Oct 2023</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://aamer98.github.io/medical_decision_transformer/">Empowering Clinicians with MeDT: A Framework for Sepsis Treatment</a> was accepted at <b>Goal-Conditioned Reinforcement Learning Workshop, NeurIPS 2023 (<strong><span style="color: red;">Spotlight</span></strong>)</b>.</div>
          </li>
          <li>
            <div><b>Oct 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://sice-si.org/SII2024/">SII</a>.</div>
          </li>
          <li>
            <div><b>Sept 2023</b>:</div>
            <div><b>Exam</b> - Passed the Ph.D. proposal exam.</div>
          </li>
          <li>
            <div><b>Jul 2023</b>:</div>
            <div><b>Paper</b> - Preprint release of our work <a href="https://arxiv.org/pdf/2307.05979.pdf"> Transformers in Reinforcement Learning: A Survey</a>.</div>
          </li>
          <li>
            <div><b>Apr 2023</b>:</div>
            <div><b>Reviewer</b> - Served as reviewer for <a href="https://iccv2023.thecvf.com/">ICCV</a> and <a href="https://ieee-iros.org/">IROS</a></b>.</div>
          </li>
          <li>
            <div><b>Dec 2022</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://arxiv.org/pdf/2211.07941.pdf">Automatic Evaluation of Excavator Operators using Learned Reward Functions</a> was accepted at <b>Reinforcement Learning for Real Life Workshop, Neurips 2022</b>.</div>
          </li>
          <li>
              <div><b>Nov 2022</b>:</div>
              <div><b>Reviewer</b> - Served as reviewer for  <a href="https://www.ieee-ras.org/publications/ra-l">Robotics and Automation Letters</a>.</div>
            </li>  
          <li>  
            <div><b>Sept 2022</b>:</div>
            <div><b>Position</b> - Fast-tracked to a PhD position at <a href="https://mila.quebec/">Mila</a>.</div>
          </li>
          <li>
            <div><b>Jun 2022</b>:</div>
            <div><b>Award</b> - Received an Exemption from International Tuition Fees for Graduate studies.</div>
          </li>
          <li>
            <div><b>Jan 2022</b>:</div>
            <div><b>Position</b> - Started Masters by Research at <a href="https://mila.quebec/">Mila</a>, in collaboration with <a href="https://www.cm-labs.com/en/">CM Labs</a>.</div>
          </li>
          <li>
            <div><b>Mar 2020</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://arxiv.org/pdf/2003.11743.pdf">Egoshots</a> was accepted at <b>Machine Learning in Real Life Workshop, ICLR 2020</b>.</div>
          </li>
          <li>
            <div><b>May 2019</b>:</div>
            <div><b>Position</b> - Started a research position at Inria.</div>
          </li>
          <li>
            <div><b>Apr 2019</b>:</div>
            <div><b>Graduation</b> - Graduated from IIIT Guwahati with President's Gold Medal.</div>
          </li>
          <li>
            <div><b>Mar 2019</b>:</div>
            <div><b>Paper</b> - Our work <a href="https://ieeexplore.ieee.org/abstract/document/8971330">Learning to synthesize faces using voice clips for Cross-Modal biometric matching</a> was accepted at IEEE Region 10 Symposium (TENSYMP).</div>
          </li>
          <li>
            <div><b>Mar 2019</b>:</div>
            <div><b>Award</b> - Received the Best Technology Award (reward of 1500 USD) by Govt. of India.</div>
          </li>
          <li>
            <div><b>May 2018</b>:</div>
            <div><b>Position</b> - Started a Research Internship at <a href="https://www.sutd.edu.sg/">Singapore University of Technology and Design</a>.</div>
          </li>
        </ul>
      </div>
            <!--<h2>Research 	&#129302;</h2>-->
        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px; width:25%; vertical-align:middle;">
              <img src="images/survey-full.gif" alt="elign" style="border-style:none;" width="350">
            </td>
            <td style="padding:20px; width:75%; vertical-align:middle;">
              <a href="https://pranavAL.github.io/transformers-in-rl-survey/">
                <papertitle>Transformers in Reinforcement Learning: A Survey</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>, 
              <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>, 
              <a href="https://mila.quebec/en/person/plstcharles/">Pierre-Luc St-Charles</a>, 
              <a href="https://www.linkedin.com/in/simon-prince-615bb9165/?originalSubdomain=ca">Simon J.D. Prince</a>, 
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em>Under Review (2023)</em>
              <br><br>
              <a href="https://arxiv.org/pdf/2307.05979.pdf">Paper</a> / 
              <a href="https://pranavAL.github.io/transformers-in-rl-survey/">Webpage</a>
              <br><br>
              <p>
                This survey explores the impact of transformers in reinforcement learning, addressing common RL challenges, while examining their applications in representation learning, policy optimization, and interpretability.
              </p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/DART.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://pranaval.github.io/DART/">
                <papertitle>Learning to Play Atari in a World of Tokens</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em> International Conference on Machine Learning (ICML), 2024</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2406.01361">Paper</a> /
              <a href="https://github.com/pranavAL/DART">Code</a> /
              <a href="https://pranaval.github.io/DART/">Webpage</a> /
              <a href="">Slides</a> 
               
              <br>
              <p>
                This work introduces Discrete Abstract Representations for Transformer-based Learning (DART), a sample-efficient method that utilizes discrete representations to improve world modeling and learning behavior in reinforcement learning, achieving superior performance on the Atari 100k benchmark compared to existing methods.
            </td>
          </tr>



          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/medt_eval_gif_title.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Empowering Clinicians with MeDT: A Framework for Sepsis Treatment</papertitle>
              </a>
              <br>
              <a href="https://aamer98.github.io/">Aamer Abdul Rahman</a>,
              <strong>Pranav Agarwal</strong>,
              <a href="https://vmichals.github.io/">Vincent Michalski</a>,
              <a href="https://www.etsmtl.ca/en/research/professors/rnoumeir/">Rita Noumeir</a>,
              <a href="https://recherche.umontreal.ca/english/our-researchers/professors-directory/researcher/is/in15318/">Philippe Jouvet</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em> NeurIPS 2023 Goal-Conditioned Reinforcement Learning Workshop (<strong><span style="color: red;">Spotlight</span></strong>)</em>. 
              <br><br>
            
              <a href="">Paper</a> /
              <a href="https://github.com/Aamer98/MeDT">Code</a> /
              <a href="https://aamer98.github.io/medical_decision_transformer/">Webpage</a> /
              <a href="">Slides</a> 
        
              <br>
              <p>
                The Medical Decision Transformer (MeDT) leverages the transformer architecture to enhance offline reinforcement learning for sepsis treatment recommendations, utilizing a goal-conditioned RL paradigm that improves interpretability and clinician interactivity, while achieving competitive results on the MIMIC-III dataset.
            </td>
          </tr> 

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TPTO.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>TPTO: A Transformer-PPO based Task Offloading Solution for Edge Computing Environments</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.ca/citations?user=z7lBJwgAAAAJ&hl=en">Niloofar Gholipour</a>,
              <a href="https://www.marcosassuncao.com/">Marcos Dias de Assuncao</a>,
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.juliengs.ca/">Julien Gascon-Samson</a>,
              <a href="https://scholar.google.com/citations?user=7xN6JqYAAAAJ&hl=en">Rajkumar Buyya</a>,
              <br><br>
              <em> IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS)</em>. 
              <br><br>
          
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10476301">Paper</a> /
              <a href="">Code</a> /
              <a href="">Webpage</a> /
              <a href="">Slides</a> 
              
              <br>
              <p>
                This paper introduces TPTO, a Deep Reinforcement Learning approach that utilizes Transformer and Proximal Policy Optimization to efficiently offload dependent IoT tasks to edge servers, significantly reducing latency for IoT applications compared to state-of-the-art methods.
              </td>
          </tr> 
                
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crane.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2211.07941.pdf">
                <papertitle>Automatic Evaluation of Excavator Operators using Learned Reward Functions</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.linkedin.com/in/marekteichmann/?originalSubdomain=ca">Marek Teichmann</a>,
              <a href="https://profs.etsmtl.ca/sandrews/">Sheldon Andrews</a>,
              <a href="https://saebrahimi.github.io/">Samira Ebrahimi Kahou</a>
              <br><br>
              <em>NeurIPS 2022 Reinforcement Learning for Real Life Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2211.07941.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/InvRL_Auto-Evaluate">Code</a> /
              <a href="https://drive.google.com/file/d/1jR1otOAu8zrY8mkhUOUZW9jkBOAKK71Z/view?usp=share_link">Video</a> /
              <a href="https://docs.google.com/presentation/d/1KEXmwOWRN_q6o5lPVk83O8mnfiCV-0kpGrnj2USp1fw/edit?usp=sharing">Slides</a>
               
              <p>A novel automatic evaluation strategy for excavator operators is proposed, utilizing machine dynamics and safety criteria, which is then validated through reinforcement learning in a simulation, resulting in safer and more realistic excavator maneuvering policies.
              </p>
            </td>
          </tr>
               

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/carla.gif" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2103.09189.pdf">
                <papertitle>Goal-constrained Sparse Reinforcement Learning for End-to-End Driving</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://www.linkedin.com/in/pierre-de-beaucorps-06064099/">Pierre de Beaucorps</a>,
              <a href="https://team.inria.fr/rits/membres/raoul-de-charette/">Raoul de Charette</a>
              <br><br>
              <em>In submission (2021)</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2103.09189.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/Goal-constrained-Sparse-Reinforcement-Learning-for-End-to-End-Driving">Code</a> /
              <a href="https://www.youtube.com/watch?v=6mD9OwrAroU">Video</a> 
               
              <br>
              <p> A curriculum-based deep reinforcement learning approach for end-to-end driving is proposed, using sparse rewards and navigation view maps to achieve generalization on unseen roads and longer distances.
</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/elign.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2003.11743.pdf">
                <papertitle>Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=fLHBgLMAAAAJ&hl=en">Alejandro Betancourt</a>,
              <a href="https://www.linkedin.com/in/vanapanagiotou/?originalSubdomain=gr">Vana Panagiotou</a>,
              <a href="https://sites.google.com/view/nataliadiaz">Natalia Diaz-Rodriguez</a>
              <br><br>
              <em>Machine Learning in Real Life (ML-IRL) ICLR 2020 Workshop</em>. 
              <br><br>
              
              <a href="https://arxiv.org/pdf/2003.11743.pdf">Paper</a> /
              <a href="https://github.com/pranavAL/Semantic_Fidelity-and-Egoshots">Code</a> /
              <a href="https://www.youtube.com/watch?v=TFzxFfI90sc">Video</a> /
              <a href="https://docs.google.com/presentation/d/1UOadIVy_CYFsFC5POjfgUxvwxST35P6kDXUp2Au4kVI/edit#slide=id.p">Slides</a>
               
              <br>
              <p>
                A new image captioning dataset, Egoshots, is introduced alongside a novel evaluation metric, Semantic Fidelity, to address biases in existing models and enable caption assessment without annotations.
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/clap.png" alt="elign" style="border-style: none" width="350">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8971330">
                <papertitle>Learning to synthesize faces using voice clips for Cross-Modal biometric matching</papertitle>
              </a>
              <br>
              <strong>Pranav Agarwal</strong>,
              <a href="https://scholar.google.com/citations?user=_MwJODcAAAAJ&hl=en">Soumyajit Poddar</a>,
              <a href="https://scholar.google.co.in/citations?user=v3U0HZ4AAAAJ&hl=en">Anakhi Hazarika</a>,
              <a href="https://scholar.google.com/citations?user=s73BsKIAAAAJ&hl=en">Hafizur Rahaman</a>
              <br><br>
              <em> 2019 IEEE Region 10 Symposium (TENSYMP)</em>. 
              <br><br>
              
              <a href="https://ieeexplore.ieee.org/abstract/document/8971330">Paper</a> /
              <a href="https://github.com/pranavAL/Cross_modal_Biometric_matching">Code</a>
              
              <br>
              <p>
                A framework for cross-modal biometric matching is proposed, generating faces from voice clips using various generative networks, with RC-GAN achieving the best identity accuracy of 84.52% and VAE producing the highest quality images.
            </td>
          </tr>

          
        </tbody></table>

      </td>
    </tr>
  </table>

<!-- Add this after your Research section -->
<section id="blogs">
  <h2 class="section-heading">Projects</h2>  
  <div class="project-grid">
    <div class="project-card">
      <img src="Projects/project1/diffusion_process_with_timesteps.gif" alt="Diffusion Models" class="project-logo">
      <div class="project-title">Diffusion Models</div>
      <div class="project-links">
        <a href="Projects/project1.html" target="_blank">Blog</a> 
        <a href="https://colab.research.google.com/drive/1JZWQqpx8QTfkOq3Vc7yaZjpN12KllqFm?usp=sharing" target="_blank">Code</a>
      </div>
      </div>
    </div>

    
    <!-- Add more project cards as needed -->
  </div>
</section>

  <table class="about-edu" width="100%">
    <tr>
      <!-- Row 1: Logos -->
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://mila.quebec/"><img src="images/mila.webp" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.etsmtl.ca/"><img src="images/ets.svg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.cm-labs.com/"><img src="images/cmlabs.jpeg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.inria.fr/en"><img src="images/inria.png" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.iiitg.ac.in/"><img src="images/iitg.jpg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://www.sutd.edu.sg/"><img src="images/sutd.jpg" width="50%"></a>
      </td>
      <td align="center" width="14%" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        <a href="https://iisc.ac.in/"><img src="images/iisc.jpg" width="50%"></a>
      </td>
    </tr>
    
    <!-- Row 2: Descriptions -->
    <tr>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        PhD Student<br><b>Mila, Québec</b><br>Jan 2022
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        PhD Student<br><b>ÉTS, Montreal</b><br>Jan 2022
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Student<br><b>CM-Labs</b><br>Jan 2022 - Sept 2022
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Assistant<br><b>Inria, Paris</b><br>May 2019 - April 2021
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        B.Tech ECE<br><b>IIIT Guwahati</b><br>Aug 2015 - May 2019
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Intern<br><b>SUTD</b><br>May 2018 - Aug 2018
      </td>
      <td align="center" style="vertical-align: middle; background-color: rgba(255, 255, 255, 1);">
        Research Intern<br><b>IISc, Bangalore</b><br>May 2017 - Aug 2017
      </td>
    </tr>
  </table>


<div style="text-align: center;">
    <div style="display: inline-block; margin-top: 40px;">
        <table class="analytics">
            <tr>
                <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=150&t=n&d=7GitBdIjM6_HrTVgbGuqjaG9RLy_0UXsikjyC2QZBVQ"></script>
            </tr>
        </table>
    </div>
</div>abl>
</div>
  
 </body>

</html>
